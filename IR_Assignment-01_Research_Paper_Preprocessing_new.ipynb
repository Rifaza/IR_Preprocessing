{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/rifaza/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/rifaza/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/rifaza/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import contractions\n",
    "import inflect\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "research_paper=\"\"\"Neural network models have shown their promising opportunities for multi-task\n",
    "learning, which focus on learning the shared layers to extract the common and\n",
    "task-invariant features. However, in most existing approaches, the extracted shared\n",
    "features are prone to be contaminated by task-specific features or the noise brought\n",
    "by other tasks. In this paper, we propose an adversarial multi-task learning framework,\n",
    "alleviating the shared and private latent feature spaces from interfering with\n",
    "each other. We conduct extensive experiments on 16 different text classification\n",
    "tasks, which demonstrates the benefits of our approach. Besides, we show that the\n",
    "shared knowledge learned by our proposed model can be regarded as off-the-shelf\n",
    "knowledge and easily transferred to new tasks.\n",
    "\n",
    "Multi-task learning is an effective approach to improve the performance of a single task with\n",
    "the help of other related tasks. Recently, neural-based models for multi-task learning have become\n",
    "very popular, ranging from computer vision (Misra et al., 2016; Zhang et al., 2014) to natural\n",
    "language processing (Collobert andWeston, 2008; Luong et al., 2015), since they provide a convenient\n",
    "way of combining information from multiple tasks.\n",
    "However, most existing work on multi-task learning (Liu et al., 2016c,b) attempts to divide the\n",
    "features of different tasks into private and shared spaces, merely based on whether parameters of some components should be shared. As shown in Figure 1-(a), the general shared-private model introduces\n",
    "two feature spaces for any task: one is used to store task-dependent features, the other is\n",
    "used to capture shared features. The major limitation of this framework is that the shared feature\n",
    "space could contain some unnecessary task-specific features, while some sharable features\n",
    "could also be mixed in private space, suffering from feature redundancy.\n",
    "Taking the following two sentences as examples, which are extracted from two different sentiment\n",
    "classification tasks: Movie reviews and Baby products reviews.\n",
    "The infantile cart is simple and easy to use. This kind of humour is infantile and boring.\n",
    "The word �infantile� indicates negative sentiment in Movie task while it is neutral in Baby task.\n",
    "However, the general shared-private model could place the task-specific word �infantile� in a\n",
    "shared space, leaving potential hazards for other tasks. Additionally, the capacity of shared space\n",
    "could also be wasted by some unnecessary features.\n",
    "To address this problem, in this paper we propose an adversarial multi-task framework, in\n",
    "which the shared and private feature spaces are in herently disjoint by introducing orthogonality constraints.Specifically, we design a generic shared private learning framework to model the text sequence.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "def denoise_text(text):\n",
    "    text = remove_between_square_brackets(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network models have shown their promising opportunities for multi-task\n",
      "learning, which focus on learning the shared layers to extract the common and\n",
      "task-invariant features. However, in most existing approaches, the extracted shared\n",
      "features are prone to be contaminated by task-specific features or the noise brought\n",
      "by other tasks. In this paper, we propose an adversarial multi-task learning framework,\n",
      "alleviating the shared and private latent feature spaces from interfering with\n",
      "each other. We conduct extensive experiments on 16 different text classification\n",
      "tasks, which demonstrates the benefits of our approach. Besides, we show that the\n",
      "shared knowledge learned by our proposed model can be regarded as off-the-shelf\n",
      "knowledge and easily transferred to new tasks.\n",
      "\n",
      "Multi-task learning is an effective approach to improve the performance of a single task with\n",
      "the help of other related tasks. Recently, neural-based models for multi-task learning have become\n",
      "very popular, ranging from computer vision (Misra et al., 2016; Zhang et al., 2014) to natural\n",
      "language processing (Collobert andWeston, 2008; Luong et al., 2015), since they provide a convenient\n",
      "way of combining information from multiple tasks.\n",
      "However, most existing work on multi-task learning (Liu et al., 2016c,b) attempts to divide the\n",
      "features of different tasks into private and shared spaces, merely based on whether parameters of some components should be shared. As shown in Figure 1-(a), the general shared-private model introduces\n",
      "two feature spaces for any task: one is used to store task-dependent features, the other is\n",
      "used to capture shared features. The major limitation of this framework is that the shared feature\n",
      "space could contain some unnecessary task-specific features, while some sharable features\n",
      "could also be mixed in private space, suffering from feature redundancy.\n",
      "Taking the following two sentences as examples, which are extracted from two different sentiment\n",
      "classification tasks: Movie reviews and Baby products reviews.\n",
      "The infantile cart is simple and easy to use. This kind of humour is infantile and boring.\n",
      "The word �infantile� indicates negative sentiment in Movie task while it is neutral in Baby task.\n",
      "However, the general shared-private model could place the task-specific word �infantile� in a\n",
      "shared space, leaving potential hazards for other tasks. Additionally, the capacity of shared space\n",
      "could also be wasted by some unnecessary features.\n",
      "To address this problem, in this paper we propose an adversarial multi-task framework, in\n",
      "which the shared and private feature spaces are in herently disjoint by introducing orthogonality constraints.Specifically, we design a generic shared private learning framework to model the text sequence.\n"
     ]
    }
   ],
   "source": [
    "research_paper = denoise_text(research_paper)\n",
    "print(research_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_contractions(text):\n",
    "    \"\"\"Replace contractions in string of text\"\"\"\n",
    "    return contractions.fix(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network models have shown their promising opportunities for multi-task\n",
      "learning, which focus on learning the shared layers to extract the common and\n",
      "task-invariant features. However, in most existing approaches, the extracted shared\n",
      "features are prone to be contaminated by task-specific features or the noise brought\n",
      "by other tasks. In this paper, we propose an adversarial multi-task learning framework,\n",
      "alleviating the shared and private latent feature spaces from interfering with\n",
      "each other. We conduct extensive experiments on 16 different text classification\n",
      "tasks, which demonstrates the benefits of our approach. Besides, we show that the\n",
      "shared knowledge learned by our proposed model can be regarded as off-the-shelf\n",
      "knowledge and easily transferred to new tasks.\n",
      "\n",
      "Multi-task learning is an effective approach to improve the performance of a single task with\n",
      "the help of other related tasks. Recently, neural-based models for multi-task learning have become\n",
      "very popular, ranging from computer vision (Misra et al., 2016; Zhang et al., 2014) to natural\n",
      "language processing (Collobert andWeston, 2008; Luong et al., 2015), since they provide a convenient\n",
      "way of combining information from multiple tasks.\n",
      "However, most existing work on multi-task learning (Liu et al., 2016c,b) attempts to divide the\n",
      "features of different tasks into private and shared spaces, merely based on whether parameters of some components should be shared. As shown in Figure 1-(a), the general shared-private model introduces\n",
      "two feature spaces for any task: one is used to store task-dependent features, the other is\n",
      "used to capture shared features. The major limitation of this framework is that the shared feature\n",
      "space could contain some unnecessary task-specific features, while some sharable features\n",
      "could also be mixed in private space, suffering from feature redundancy.\n",
      "Taking the following two sentences as examples, which are extracted from two different sentiment\n",
      "classification tasks: Movie reviews and Baby products reviews.\n",
      "The infantile cart is simple and easy to use. This kind of humour is infantile and boring.\n",
      "The word �infantile� indicates negative sentiment in Movie task while it is neutral in Baby task.\n",
      "However, the general shared-private model could place the task-specific word �infantile� in a\n",
      "shared space, leaving potential hazards for other tasks. Additionally, the capacity of shared space\n",
      "could also be wasted by some unnecessary features.\n",
      "To address this problem, in this paper we propose an adversarial multi-task framework, in\n",
      "which the shared and private feature spaces are in herently disjoint by introducing orthogonality constraints.Specifically, we design a generic shared private learning framework to model the text sequence.\n"
     ]
    }
   ],
   "source": [
    "research_paper_text = replace_contractions(research_paper)\n",
    "print(research_paper_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Neural', 'network', 'models', 'have', 'shown', 'their', 'promising', 'opportunities', 'for', 'multi-task', 'learning', ',', 'which', 'focus', 'on', 'learning', 'the', 'shared', 'layers', 'to', 'extract', 'the', 'common', 'and', 'task-invariant', 'features', '.', 'However', ',', 'in', 'most', 'existing', 'approaches', ',', 'the', 'extracted', 'shared', 'features', 'are', 'prone', 'to', 'be', 'contaminated', 'by', 'task-specific', 'features', 'or', 'the', 'noise', 'brought', 'by', 'other', 'tasks', '.', 'In', 'this', 'paper', ',', 'we', 'propose', 'an', 'adversarial', 'multi-task', 'learning', 'framework', ',', 'alleviating', 'the', 'shared', 'and', 'private', 'latent', 'feature', 'spaces', 'from', 'interfering', 'with', 'each', 'other', '.', 'We', 'conduct', 'extensive', 'experiments', 'on', '16', 'different', 'text', 'classification', 'tasks', ',', 'which', 'demonstrates', 'the', 'benefits', 'of', 'our', 'approach', '.', 'Besides', ',', 'we', 'show', 'that', 'the', 'shared', 'knowledge', 'learned', 'by', 'our', 'proposed', 'model', 'can', 'be', 'regarded', 'as', 'off-the-shelf', 'knowledge', 'and', 'easily', 'transferred', 'to', 'new', 'tasks', '.', 'Multi-task', 'learning', 'is', 'an', 'effective', 'approach', 'to', 'improve', 'the', 'performance', 'of', 'a', 'single', 'task', 'with', 'the', 'help', 'of', 'other', 'related', 'tasks', '.', 'Recently', ',', 'neural-based', 'models', 'for', 'multi-task', 'learning', 'have', 'become', 'very', 'popular', ',', 'ranging', 'from', 'computer', 'vision', '(', 'Misra', 'et', 'al.', ',', '2016', ';', 'Zhang', 'et', 'al.', ',', '2014', ')', 'to', 'natural', 'language', 'processing', '(', 'Collobert', 'andWeston', ',', '2008', ';', 'Luong', 'et', 'al.', ',', '2015', ')', ',', 'since', 'they', 'provide', 'a', 'convenient', 'way', 'of', 'combining', 'information', 'from', 'multiple', 'tasks', '.', 'However', ',', 'most', 'existing', 'work', 'on', 'multi-task', 'learning', '(', 'Liu', 'et', 'al.', ',', '2016c', ',', 'b', ')', 'attempts', 'to', 'divide', 'the', 'features', 'of', 'different', 'tasks', 'into', 'private', 'and', 'shared', 'spaces', ',', 'merely', 'based', 'on', 'whether', 'parameters', 'of', 'some', 'components', 'should', 'be', 'shared', '.', 'As', 'shown', 'in', 'Figure', '1-', '(', 'a', ')', ',', 'the', 'general', 'shared-private', 'model', 'introduces', 'two', 'feature', 'spaces', 'for', 'any', 'task', ':', 'one', 'is', 'used', 'to', 'store', 'task-dependent', 'features', ',', 'the', 'other', 'is', 'used', 'to', 'capture', 'shared', 'features', '.', 'The', 'major', 'limitation', 'of', 'this', 'framework', 'is', 'that', 'the', 'shared', 'feature', 'space', 'could', 'contain', 'some', 'unnecessary', 'task-specific', 'features', ',', 'while', 'some', 'sharable', 'features', 'could', 'also', 'be', 'mixed', 'in', 'private', 'space', ',', 'suffering', 'from', 'feature', 'redundancy', '.', 'Taking', 'the', 'following', 'two', 'sentences', 'as', 'examples', ',', 'which', 'are', 'extracted', 'from', 'two', 'different', 'sentiment', 'classification', 'tasks', ':', 'Movie', 'reviews', 'and', 'Baby', 'products', 'reviews', '.', 'The', 'infantile', 'cart', 'is', 'simple', 'and', 'easy', 'to', 'use', '.', 'This', 'kind', 'of', 'humour', 'is', 'infantile', 'and', 'boring', '.', 'The', 'word', '�infantile�', 'indicates', 'negative', 'sentiment', 'in', 'Movie', 'task', 'while', 'it', 'is', 'neutral', 'in', 'Baby', 'task', '.', 'However', ',', 'the', 'general', 'shared-private', 'model', 'could', 'place', 'the', 'task-specific', 'word', '�infantile�', 'in', 'a', 'shared', 'space', ',', 'leaving', 'potential', 'hazards', 'for', 'other', 'tasks', '.', 'Additionally', ',', 'the', 'capacity', 'of', 'shared', 'space', 'could', 'also', 'be', 'wasted', 'by', 'some', 'unnecessary', 'features', '.', 'To', 'address', 'this', 'problem', ',', 'in', 'this', 'paper', 'we', 'propose', 'an', 'adversarial', 'multi-task', 'framework', ',', 'in', 'which', 'the', 'shared', 'and', 'private', 'feature', 'spaces', 'are', 'in', 'herently', 'disjoint', 'by', 'introducing', 'orthogonality', 'constraints.Specifically', ',', 'we', 'design', 'a', 'generic', 'shared', 'private', 'learning', 'framework', 'to', 'model', 'the', 'text', 'sequence', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenised_research_paper = nltk.word_tokenize(research_paper_text)\n",
    "print(tokenised_research_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neural', 'network', 'models', 'shown', 'promising', 'opportunities', 'multitask', 'learning', 'focus', 'learning', 'shared', 'layers', 'extract', 'common', 'taskinvariant', 'features', 'however', 'existing', 'approaches', 'extracted', 'shared', 'features', 'prone', 'contaminated', 'taskspecific', 'features', 'noise', 'brought', 'tasks', 'paper', 'propose', 'adversarial', 'multitask', 'learning', 'framework', 'alleviating', 'shared', 'private', 'latent', 'feature', 'spaces', 'interfering', 'conduct', 'extensive', 'experiments', 'sixteen', 'different', 'text', 'classification', 'tasks', 'demonstrates', 'benefits', 'approach', 'besides', 'show', 'shared', 'knowledge', 'learned', 'proposed', 'model', 'regarded', 'offtheshelf', 'knowledge', 'easily', 'transferred', 'new', 'tasks', 'multitask', 'learning', 'effective', 'approach', 'improve', 'performance', 'single', 'task', 'help', 'related', 'tasks', 'recently', 'neuralbased', 'models', 'multitask', 'learning', 'become', 'popular', 'ranging', 'computer', 'vision', 'misra', 'et', 'al', 'two thousand and sixteen', 'zhang', 'et', 'al', 'two thousand and fourteen', 'natural', 'language', 'processing', 'collobert', 'andweston', 'two thousand and eight', 'luong', 'et', 'al', 'two thousand and fifteen', 'since', 'provide', 'convenient', 'way', 'combining', 'information', 'multiple', 'tasks', 'however', 'existing', 'work', 'multitask', 'learning', 'liu', 'et', 'al', '2016c', 'b', 'attempts', 'divide', 'features', 'different', 'tasks', 'private', 'shared', 'spaces', 'merely', 'based', 'whether', 'parameters', 'components', 'shared', 'shown', 'figure', 'one', 'general', 'sharedprivate', 'model', 'introduces', 'two', 'feature', 'spaces', 'task', 'one', 'used', 'store', 'taskdependent', 'features', 'used', 'capture', 'shared', 'features', 'major', 'limitation', 'framework', 'shared', 'feature', 'space', 'could', 'contain', 'unnecessary', 'taskspecific', 'features', 'sharable', 'features', 'could', 'also', 'mixed', 'private', 'space', 'suffering', 'feature', 'redundancy', 'taking', 'following', 'two', 'sentences', 'examples', 'extracted', 'two', 'different', 'sentiment', 'classification', 'tasks', 'movie', 'reviews', 'baby', 'products', 'reviews', 'infantile', 'cart', 'simple', 'easy', 'use', 'kind', 'humour', 'infantile', 'boring', 'word', 'infantile', 'indicates', 'negative', 'sentiment', 'movie', 'task', 'neutral', 'baby', 'task', 'however', 'general', 'sharedprivate', 'model', 'could', 'place', 'taskspecific', 'word', 'infantile', 'shared', 'space', 'leaving', 'potential', 'hazards', 'tasks', 'additionally', 'capacity', 'shared', 'space', 'could', 'also', 'wasted', 'unnecessary', 'features', 'address', 'problem', 'paper', 'propose', 'adversarial', 'multitask', 'framework', 'shared', 'private', 'feature', 'spaces', 'herently', 'disjoint', 'introducing', 'orthogonality', 'constraintsspecifically', 'design', 'generic', 'shared', 'private', 'learning', 'framework', 'model', 'text', 'sequence']\n"
     ]
    }
   ],
   "source": [
    "words_research_paper = normalize(tokenised_research_paper)\n",
    "print(words_research_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research Paper - Stemmed:\n",
      " ['neur', 'network', 'model', 'shown', 'prom', 'opportun', 'multitask', 'learn', 'foc', 'learn', 'shar', 'lay', 'extract', 'common', 'taskinv', 'feat', 'howev', 'ex', 'approach', 'extract', 'shar', 'feat', 'pron', 'contamin', 'taskspec', 'feat', 'nois', 'brought', 'task', 'pap', 'propos', 'advers', 'multitask', 'learn', 'framework', 'allevy', 'shar', 'priv', 'lat', 'feat', 'spac', 'interf', 'conduc', 'extend', 'expery', 'sixteen', 'diff', 'text', 'class', 'task', 'demonst', 'benefit', 'approach', 'besid', 'show', 'shar', 'knowledg', 'learn', 'propos', 'model', 'regard', 'offtheshelf', 'knowledg', 'easy', 'transfer', 'new', 'task', 'multitask', 'learn', 'effect', 'approach', 'improv', 'perform', 'singl', 'task', 'help', 'rel', 'task', 'rec', 'neuralbas', 'model', 'multitask', 'learn', 'becom', 'popul', 'rang', 'comput', 'vis', 'misr', 'et', 'al', 'two thousand and sixteen', 'zhang', 'et', 'al', 'two thousand and fourteen', 'nat', 'langu', 'process', 'collobert', 'andweston', 'two thousand and eight', 'luong', 'et', 'al', 'two thousand and fifteen', 'sint', 'provid', 'conveny', 'way', 'combin', 'inform', 'multipl', 'task', 'howev', 'ex', 'work', 'multitask', 'learn', 'liu', 'et', 'al', '2016c', 'b', 'attempt', 'divid', 'feat', 'diff', 'task', 'priv', 'shar', 'spac', 'mer', 'bas', 'wheth', 'paramet', 'compon', 'shar', 'shown', 'fig', 'on', 'gen', 'sharedpr', 'model', 'introduc', 'two', 'feat', 'spac', 'task', 'on', 'us', 'stor', 'taskdepend', 'feat', 'us', 'capt', 'shar', 'feat', 'maj', 'limit', 'framework', 'shar', 'feat', 'spac', 'could', 'contain', 'unnecess', 'taskspec', 'feat', 'shar', 'feat', 'could', 'also', 'mix', 'priv', 'spac', 'suff', 'feat', 'redund', 'tak', 'follow', 'two', 'sent', 'exampl', 'extract', 'two', 'diff', 'senty', 'class', 'task', 'movy', 'review', 'baby', 'produc', 'review', 'infantil', 'cart', 'simpl', 'easy', 'us', 'kind', 'humo', 'infantil', 'bor', 'word', 'infantil', 'ind', 'neg', 'senty', 'movy', 'task', 'neut', 'baby', 'task', 'howev', 'gen', 'sharedpr', 'model', 'could', 'plac', 'taskspec', 'word', 'infantil', 'shar', 'spac', 'leav', 'pot', 'hazard', 'task', 'addit', 'capac', 'shar', 'spac', 'could', 'also', 'wast', 'unnecess', 'feat', 'address', 'problem', 'pap', 'propos', 'advers', 'multitask', 'framework', 'shar', 'priv', 'feat', 'spac', 'her', 'disjoint', 'introduc', 'orthogon', 'constraintsspec', 'design', 'gen', 'shar', 'priv', 'learn', 'framework', 'model', 'text', 'sequ']\n",
      "\n",
      " ResearchPaper - Lemmatized:\n",
      " ['neural', 'network', 'model', 'show', 'promise', 'opportunities', 'multitask', 'learn', 'focus', 'learn', 'share', 'layer', 'extract', 'common', 'taskinvariant', 'feature', 'however', 'exist', 'approach', 'extract', 'share', 'feature', 'prone', 'contaminate', 'taskspecific', 'feature', 'noise', 'bring', 'task', 'paper', 'propose', 'adversarial', 'multitask', 'learn', 'framework', 'alleviate', 'share', 'private', 'latent', 'feature', 'space', 'interfere', 'conduct', 'extensive', 'experiment', 'sixteen', 'different', 'text', 'classification', 'task', 'demonstrate', 'benefit', 'approach', 'besides', 'show', 'share', 'knowledge', 'learn', 'propose', 'model', 'regard', 'offtheshelf', 'knowledge', 'easily', 'transfer', 'new', 'task', 'multitask', 'learn', 'effective', 'approach', 'improve', 'performance', 'single', 'task', 'help', 'relate', 'task', 'recently', 'neuralbased', 'model', 'multitask', 'learn', 'become', 'popular', 'range', 'computer', 'vision', 'misra', 'et', 'al', 'two thousand and sixteen', 'zhang', 'et', 'al', 'two thousand and fourteen', 'natural', 'language', 'process', 'collobert', 'andweston', 'two thousand and eight', 'luong', 'et', 'al', 'two thousand and fifteen', 'since', 'provide', 'convenient', 'way', 'combine', 'information', 'multiple', 'task', 'however', 'exist', 'work', 'multitask', 'learn', 'liu', 'et', 'al', '2016c', 'b', 'attempt', 'divide', 'feature', 'different', 'task', 'private', 'share', 'space', 'merely', 'base', 'whether', 'parameters', 'components', 'share', 'show', 'figure', 'one', 'general', 'sharedprivate', 'model', 'introduce', 'two', 'feature', 'space', 'task', 'one', 'use', 'store', 'taskdependent', 'feature', 'use', 'capture', 'share', 'feature', 'major', 'limitation', 'framework', 'share', 'feature', 'space', 'could', 'contain', 'unnecessary', 'taskspecific', 'feature', 'sharable', 'feature', 'could', 'also', 'mix', 'private', 'space', 'suffer', 'feature', 'redundancy', 'take', 'follow', 'two', 'sentence', 'examples', 'extract', 'two', 'different', 'sentiment', 'classification', 'task', 'movie', 'review', 'baby', 'products', 'review', 'infantile', 'cart', 'simple', 'easy', 'use', 'kind', 'humour', 'infantile', 'bore', 'word', 'infantile', 'indicate', 'negative', 'sentiment', 'movie', 'task', 'neutral', 'baby', 'task', 'however', 'general', 'sharedprivate', 'model', 'could', 'place', 'taskspecific', 'word', 'infantile', 'share', 'space', 'leave', 'potential', 'hazard', 'task', 'additionally', 'capacity', 'share', 'space', 'could', 'also', 'waste', 'unnecessary', 'feature', 'address', 'problem', 'paper', 'propose', 'adversarial', 'multitask', 'framework', 'share', 'private', 'feature', 'space', 'herently', 'disjoint', 'introduce', 'orthogonality', 'constraintsspecifically', 'design', 'generic', 'share', 'private', 'learn', 'framework', 'model', 'text', 'sequence']\n"
     ]
    }
   ],
   "source": [
    "def stem_and_lemmatize(words):\n",
    "    stems = stem_words(words)\n",
    "    lemmas = lemmatize_verbs(words)\n",
    "    return stems, lemmas\n",
    "\n",
    "stems, lemmas = stem_and_lemmatize(words_research_paper)\n",
    "print('Research Paper - Stemmed:\\n', stems)\n",
    "print('\\n ResearchPaper - Lemmatized:\\n', lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "def correct_sentence_spelling(sentence):\n",
    "    \n",
    "    sentence = TextBlob(sentence)\n",
    "    \n",
    "    result = sentence.correct()\n",
    "    \n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_word_spelling(word):\n",
    "    \n",
    "    word = Word(word)\n",
    "    \n",
    "    result = word.correct()\n",
    "    \n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in words_research_paper:\n",
    "    correct_word_spelling(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
